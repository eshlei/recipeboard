{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import os\n",
    "import numpy as np\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 13516)\t0.06237905773963521\n",
      "  (0, 2937)\t0.018111406059540213\n",
      "  (0, 8936)\t0.05919150684818298\n",
      "  (0, 15751)\t0.0235798831506239\n",
      "  (0, 16341)\t0.06186615086718817\n",
      "  (0, 7321)\t0.05099638063026148\n",
      "  (0, 8550)\t0.04290112668668134\n",
      "  (0, 3053)\t0.03806218313525274\n",
      "  (0, 9494)\t0.029383548483780206\n",
      "  (0, 4656)\t0.04479347580324897\n",
      "  (0, 2904)\t0.06237905773963521\n",
      "  (0, 7852)\t0.0703769397574735\n",
      "  (0, 16751)\t0.01900485255890835\n",
      "  (0, 8193)\t0.04197009730298661\n",
      "  (0, 2845)\t0.023874342632050346\n",
      "  (0, 11178)\t0.06469449750734417\n",
      "  (0, 13199)\t0.06679821565183505\n",
      "  (0, 2570)\t0.060451503394460426\n",
      "  (0, 6871)\t0.020972478926810197\n",
      "  (0, 16561)\t0.026784792016567808\n",
      "  (0, 8273)\t0.03061930082690929\n",
      "  (0, 7587)\t0.024291899879021032\n",
      "  (0, 14943)\t0.09004718367427564\n",
      "  (0, 11054)\t0.03189088028002332\n",
      "  (0, 7082)\t0.02197119018442222\n",
      "  :\t:\n",
      "  (1801, 15534)\t0.019504860445106038\n",
      "  (1801, 10327)\t0.013021981975041055\n",
      "  (1801, 7278)\t0.0713163631596032\n",
      "  (1801, 14517)\t0.041028833311643906\n",
      "  (1801, 15509)\t0.09233350815018795\n",
      "  (1801, 2785)\t0.12674750358000167\n",
      "  (1801, 13233)\t0.015159532884807491\n",
      "  (1801, 16658)\t0.03546087473811218\n",
      "  (1801, 3775)\t0.03355036705279369\n",
      "  (1801, 8592)\t0.08083664186193508\n",
      "  (1801, 11802)\t0.01933988853560202\n",
      "  (1801, 8801)\t0.07398599185014906\n",
      "  (1801, 5513)\t0.021960143862943125\n",
      "  (1801, 14737)\t0.15716942028244557\n",
      "  (1801, 7261)\t0.17454917759416408\n",
      "  (1801, 10186)\t0.15474472700231595\n",
      "  (1801, 11160)\t0.1548772230508827\n",
      "  (1801, 8693)\t0.03929264398976521\n",
      "  (1801, 2648)\t0.015624532225131235\n",
      "  (1801, 7538)\t0.026853146039304297\n",
      "  (1801, 12604)\t0.05758055679605411\n",
      "  (1801, 4861)\t0.011516111359210822\n",
      "  (1801, 2666)\t0.011516111359210822\n",
      "  (1801, 16791)\t0.011516111359210822\n",
      "  (1801, 8421)\t0.011516111359210822\n"
     ]
    }
   ],
   "source": [
    "db = {\n",
    "    \"users\": {},\n",
    "    \"liked\": {},\n",
    "    \"disliked\": {}\n",
    "}\n",
    "\n",
    "def load_recipes(directory='data/allrecipes/recipes'):\n",
    "    recipes = []\n",
    "    file_names = []\n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.endswith('.txt'):\n",
    "            with open(os.path.join(directory, file_name), 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "                recipes.append(content)\n",
    "                file_names.append(file_name)\n",
    "    return recipes, file_names\n",
    "\n",
    "recipes, file_names = load_recipes()\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(recipes)\n",
    "print(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.20539199 0.12076247 ... 0.31386641 0.1333043  0.25090498]\n",
      " [0.20539199 1.         0.13286921 ... 0.21056733 0.13214875 0.19507694]\n",
      " [0.12076247 0.13286921 1.         ... 0.17750994 0.17635317 0.14033873]\n",
      " ...\n",
      " [0.31386641 0.21056733 0.17750994 ... 1.         0.16861203 0.22072519]\n",
      " [0.1333043  0.13214875 0.17635317 ... 0.16861203 1.         0.13986733]\n",
      " [0.25090498 0.19507694 0.14033873 ... 0.22072519 0.13986733 1.        ]]\n",
      "Recommended docs: ['6687.txt', '16952.txt', '20144.txt', '104999.txt', '241707.txt', '268920.txt', '219967.txt', '41679.txt', '20153.txt', '222082.txt']\n",
      "Cuisine-specific docs: []\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scores = cosine_similarity(tfidf_matrix)\n",
    "def get_docs(user_id, relevant=True):\n",
    "    user_likes = db[\"liked\"].get(user_id, [])\n",
    "    user_dislikes = db[\"disliked\"].get(user_id, [])\n",
    "    \n",
    "    if user_likes:\n",
    "        doc_index = file_names.index(user_likes[0]) \n",
    "        similarity_scores = scores[doc_index]\n",
    "    else:\n",
    "        similarity_scores = np.mean(scores, axis=0)\n",
    "    \n",
    "    relevant_docs = [file_names[idx] for idx in np.argsort(similarity_scores)[::-1]]\n",
    "    if relevant:\n",
    "        return relevant_docs[:10] \n",
    "    else:\n",
    "        return [doc for doc in file_names if doc not in relevant_docs][:10]\n",
    "def apply_feedback(user_id, doc_id, like=True):\n",
    "    if like:\n",
    "        db[\"liked\"].setdefault(user_id, []).append(doc_id)\n",
    "    else:\n",
    "        db[\"disliked\"].setdefault(user_id, []).append(doc_id)\n",
    "\n",
    "def get_cuisine_docs(cuisine_type):\n",
    "    relevant_docs = [doc for doc in file_names if cuisine_type.lower() in doc.lower()]\n",
    "    return relevant_docs[:10]\n",
    "\n",
    "user_id = \"user123\"\n",
    "apply_feedback(user_id, \"6687.txt\", like=True)\n",
    "print(\"Recommended docs:\", get_docs(user_id))\n",
    "print(\"Cuisine-specific docs:\", get_cuisine_docs(\"Italian\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_recipes = [recipe.lower().split() for recipe in recipes]\n",
    "word2vec_model = Word2Vec(sentences=tokenized_recipes, vector_size=100, window=5, min_count=1, sg=1)\n",
    "\n",
    "def generate_recipe_embeddings(recipes):\n",
    "    embeddings = []\n",
    "    for recipe in recipes:\n",
    "        words = recipe.lower().split()\n",
    "        valid_words = [word for word in words if word in word2vec_model.wv]\n",
    "        if valid_words:\n",
    "            recipe_vector = np.mean([word2vec_model.wv[word] for word in valid_words], axis=0)\n",
    "        else:\n",
    "            recipe_vector = np.zeros(word2vec_model.vector_size)\n",
    "        embeddings.append(recipe_vector)\n",
    "    return np.array(embeddings)\n",
    "\n",
    "recipe_embeddings = generate_recipe_embeddings(recipes)\n",
    "scores = cosine_similarity(recipe_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6687.txt',\n",
       " '6697.txt',\n",
       " '6770.txt',\n",
       " '241707.txt',\n",
       " '229351.txt',\n",
       " '7603.txt',\n",
       " '21387.txt',\n",
       " '7860.txt',\n",
       " '255621.txt',\n",
       " '6932.txt']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_docs(user_id, relevant=True):\n",
    "    user_likes = db[\"liked\"].get(user_id, [])\n",
    "    \n",
    "    if user_likes:\n",
    "        liked_indices = [file_names.index(doc) for doc in user_likes if doc in file_names]\n",
    "        if liked_indices:\n",
    "            liked_embeddings = recipe_embeddings[liked_indices]\n",
    "            similarity_scores = np.mean(cosine_similarity(liked_embeddings, recipe_embeddings), axis=0)\n",
    "        else:\n",
    "            similarity_scores = np.mean(scores, axis=0)\n",
    "    else:\n",
    "        similarity_scores = np.mean(scores, axis=0)\n",
    "    \n",
    "    relevant_docs = [file_names[idx] for idx in np.argsort(similarity_scores)[::-1]]\n",
    "    if relevant:\n",
    "        return relevant_docs[:10]  \n",
    "    else:\n",
    "        return [doc for doc in file_names if doc not in relevant_docs][:10]  \n",
    "\n",
    "user_id = \"user123\"\n",
    "apply_feedback(user_id, \"6687.txt\", like=True)\n",
    "apply_feedback(user_id, \"1324.txt\", like=True)\n",
    "\n",
    "recommended_docs = get_docs(user_id)\n",
    "\n",
    "recommended_docs\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
